{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Lab 2 Assignment (MLFlow)\n",
    "\n",
    "Author: Grant Nitta\n",
    "\n",
    "Date Created: 03/20/2025\n",
    "\n",
    "Date Last Modified: 03/21/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Once you have selected a set of data, create a brand new experiment in MLFlow and begin exploring your data. Do some EDA, clean up, and learn about your data. You do not need to begin tracking anything yet, but you can if you want to (e.g. you can log different versions of your data as you clean it up and do any feature engineering). Do not spend a ton of time on this part. Your goal isn't really to build a great model, so don't spend hours on feature engineering and missing data imputation and things like that.\n",
    "\n",
    "Once your data is clean, begin training models and tracking your experiments. If you intend to use this same dataset for your final project, then start thinking about what your model might look like when you actually deploy it. For example, when you engineer new features, be sure to save the code that does this, as you will need this in the future. If your final model has 1000 complex features, you might have a difficult time deploying it later on. If your final model takes 15 minutes to train, or takes a long time to score a new batch of data, you may want to think about training a less complex model.\n",
    "\n",
    "Now, when tracking your experiments, at a *minimum*, you should:\n",
    "\n",
    "1. Try at least 3 different ML algorithms (e.g. linear regression, decision tree, random forest, etc.).\n",
    "2. Do hyperparameter tuning for **each** algorithm.\n",
    "3. Do some very basic feature selection, and repeat the above steps with these reduced sets of features.\n",
    "4. Identify the top 3 best models and note these down for later.\n",
    "6. Choose the **final** \"best\" model that you would deploy or use on future data, stage it (in MLFlow), and run it on the test set to get a final measure of performance. Don't forget to log the test set metric.\n",
    "7. Be sure you logged the exact training, validation, and testing datasets for the 3 best models, as well as hyperparameter values, and the values of your metrics.  \n",
    "8. Push your code to Github. No need to track the mlruns folder, the images folder, any datasets, or the sqlite database in git.\n",
    "\n",
    "### Turning It In\n",
    "\n",
    "In the MLFlow UI, next to the refresh button you should see three vertical dots. Click the dots and then download your experiments as a csv file. Open the csv file in Excel and highlight the rows for your top 3 models from step 4, highlight the run where you applied your best model to the test set, and then save as an excel file. Take a snapshot of the Models page in the MLFLow UI showing the model you staged in step 6 above. Submit the excel file and the snapshot to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ucimlrepo\n",
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "# student_performance = fetch_ucirepo(id=320)\n",
    "\n",
    "# # data (as pandas dataframes)\n",
    "# X = student_performance.data.features\n",
    "# y = student_performance.data.targets\n",
    "\n",
    "# metadata\n",
    "# print(student_performance.metadata)\n",
    "\n",
    "# # variable information\n",
    "# print(student_performance.variables)\n",
    "\n",
    "# fetch dataset\n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = iris.data.features\n",
    "y = iris.data.targets\n",
    "\n",
    "# metadata\n",
    "# print(iris.metadata)\n",
    "\n",
    "# # variable information\n",
    "# print(iris.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:45:05 INFO mlflow.tracking.fluent: Experiment with name 'Lab2-student_performance_Iris' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/skier/MSDS/Spring2/Spring2-MSDS-MLOps/labs/lab2/mlruns/12', creation_time=1742622305659, experiment_id='12', last_update_time=1742622305659, lifecycle_stage='active', name='Lab2-student_performance_Iris', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Lab2-student_performance_Iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = X.copy()\n",
    "\n",
    "# Track column transformations\n",
    "column_mapping = {}\n",
    "label_encoders = {}\n",
    "\n",
    "# Find all object and category columns\n",
    "string_columns = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "for col in string_columns:\n",
    "    # For columns with many unique values, use label encoding\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col + \"_encoded\"] = le.fit_transform(X[col])\n",
    "\n",
    "    # Drop the original column\n",
    "    X_encoded = X_encoded.drop(col, axis=1)\n",
    "\n",
    "    # Store mapping information\n",
    "    column_mapping[col] = [col + \"_encoded\"]\n",
    "    label_encoders[col] = le\n",
    "\n",
    "X_encoded = X_encoded.astype(float)\n",
    "# y_use = y[\"G1\"]\n",
    "y_use = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_use, test_size=0.2, shuffle=True\n",
    ")\n",
    "X_train_val, X_val, y_train_val, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        classifier_type = params[\"type\"]\n",
    "        del params[\"type\"]\n",
    "        if classifier_type == \"dt\":\n",
    "            clf = DecisionTreeClassifier(**params)\n",
    "        elif classifier_type == \"rf\":\n",
    "            clf = RandomForestClassifier(**params)\n",
    "        elif classifier_type == \"gb\":\n",
    "            clf = GradientBoostingClassifier(**params)\n",
    "        else:\n",
    "            return 0\n",
    "        acc = cross_val_score(clf, X_train_val, y_train_val).mean()\n",
    "\n",
    "        mlflow.set_tag(\"Model\", classifier_type)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.end_run()\n",
    "        return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "search_space = hp.choice(\n",
    "    \"classifier_type\",\n",
    "    [\n",
    "        {\n",
    "            \"type\": \"dt\",\n",
    "            \"criterion\": hp.choice(\"dtree_criterion\", [\"gini\", \"entropy\"]),\n",
    "            \"max_depth\": hp.choice(\n",
    "                \"dtree_max_depth\",\n",
    "                [None, hp.randint(\"dtree_max_depth_int\", 1, 10)],\n",
    "            ),\n",
    "            \"min_samples_split\": hp.randint(\"dtree_min_samples_split\", 2, 10),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"rf\",\n",
    "            \"n_estimators\": hp.randint(\"rf_n_estimators\", 20, 500),\n",
    "            \"max_features\": hp.randint(\"rf_max_features\", 2, 9),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"gb\",\n",
    "            \"loss\": hp.choice(\"gb_loss\", [\"log_loss\"]),\n",
    "            \"learning_rate\": hp.uniform(\"gb_learning_rate\", 0.05, 2),\n",
    "            \"n_estimators\": hp.randint(\"gb_n_estimators\", 20, 500),\n",
    "            \"subsample\": hp.uniform(\"gb_subsample\", 0.1, 1),\n",
    "            \"criterion\": hp.choice(\n",
    "                \"gb_criterion\", [\"friedman_mse\", \"squared_error\"]\n",
    "            ),\n",
    "            \"max_depth\": hp.choice(\n",
    "                \"gb_max_depth\",\n",
    "                [None, hp.randint(\"gb_max_depth_int\", 1, 10)],\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "algo = tpe.suggest\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:10<00:00,  2.96trial/s, best loss: -0.9689473684210526]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier_type': 2,\n",
       " 'gb_criterion': 1,\n",
       " 'gb_learning_rate': 0.7967696607938101,\n",
       " 'gb_loss': 0,\n",
       " 'gb_max_depth': 0,\n",
       " 'gb_n_estimators': 211,\n",
       " 'gb_subsample': 0.4209379501392708}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective, space=search_space, algo=algo, max_evals=32, trials=trials\n",
    ")\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "sepal length\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "X_redcued_train = X_train.copy()\n",
    "VIF = [0]\n",
    "while len(VIF) > 0:\n",
    "    X_numeric = pd.DataFrame()\n",
    "    for col in X_redcued_train.columns:\n",
    "        # Force everything through string conversion to be safe\n",
    "        X_numeric[col] = pd.to_numeric(\n",
    "            X_train[col].astype(str), errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    # Now calculate VIF\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_numeric.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X_numeric.values, i)\n",
    "        for i in range(X_numeric.shape[1])\n",
    "    ]\n",
    "    vif_test = vif_data.set_index(\"Feature\").sort_values(\n",
    "        by=\"VIF\", ascending=False\n",
    "    )\n",
    "    if vif_test.max().iloc[0] > 5:\n",
    "        print(VIF)\n",
    "        VIF = vif_test.idxmax().iloc[0]\n",
    "        X_redcued_train.drop(VIF, axis=1, inplace=True)\n",
    "    else:\n",
    "        print(\"Stopping\")\n",
    "        VIF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        classifier_type = params[\"type\"]\n",
    "        del params[\"type\"]\n",
    "        if classifier_type == \"dt\":\n",
    "            clf = DecisionTreeClassifier(**params)\n",
    "        elif classifier_type == \"rf\":\n",
    "            clf = RandomForestClassifier(**params)\n",
    "        elif classifier_type == \"gb\":\n",
    "            clf = GradientBoostingClassifier(**params)\n",
    "        else:\n",
    "            return 0\n",
    "        acc = cross_val_score(clf, X_redcued_train, y_train).mean()\n",
    "\n",
    "        mlflow.set_tag(\"Model\", classifier_type)\n",
    "        mlflow.set_tag(\"Data\", \"Training\")\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.sklearn.log_model(clf, artifact_path=\"better_models\")\n",
    "        mlflow.end_run()\n",
    "        return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "search_space = hp.choice(\n",
    "    \"classifier_type\",\n",
    "    [\n",
    "        {\n",
    "            \"type\": \"dt\",\n",
    "            \"criterion\": hp.choice(\"dtree_criterion\", [\"gini\", \"entropy\"]),\n",
    "            \"max_depth\": hp.choice(\n",
    "                \"dtree_max_depth\",\n",
    "                [None, hp.randint(\"dtree_max_depth_int\", 1, 10)],\n",
    "            ),\n",
    "            \"min_samples_split\": hp.randint(\"dtree_min_samples_split\", 2, 10),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"rf\",\n",
    "            \"n_estimators\": hp.randint(\"rf_n_estimators\", 20, 500),\n",
    "            \"max_features\": hp.randint(\"rf_max_features\", 2, 9),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"gb\",\n",
    "            \"loss\": hp.choice(\"gb_loss\", [\"log_loss\"]),\n",
    "            \"learning_rate\": hp.uniform(\"gb_learning_rate\", 0.05, 2),\n",
    "            \"n_estimators\": hp.randint(\"gb_n_estimators\", 20, 500),\n",
    "            \"subsample\": hp.uniform(\"gb_subsample\", 0.1, 1),\n",
    "            \"criterion\": hp.choice(\n",
    "                \"gb_criterion\", [\"friedman_mse\", \"squared_error\"]\n",
    "            ),\n",
    "            \"max_depth\": hp.choice(\n",
    "                \"gb_max_depth\",\n",
    "                [None, hp.randint(\"gb_max_depth_int\", 1, 10)],\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "algo = tpe.suggest\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:25 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:01<00:39,  1.26s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/32 [00:02<00:41,  1.37s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [00:03<00:33,  1.16s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:29 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [00:05<00:35,  1.25s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/32 [00:06<00:33,  1.24s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:31 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/32 [00:07<00:29,  1.12s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:33 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [00:08<00:30,  1.23s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:34 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 8/32 [00:09<00:27,  1.16s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [00:11<00:29,  1.28s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 10/32 [00:12<00:25,  1.15s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:37 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 11/32 [00:13<00:25,  1.21s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 12/32 [00:15<00:27,  1.37s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [00:16<00:25,  1.37s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [00:18<00:28,  1.57s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 15/32 [00:19<00:23,  1.38s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:45 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 16/32 [00:20<00:22,  1.40s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [00:21<00:18,  1.25s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 18/32 [00:23<00:19,  1.40s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 19/32 [00:24<00:16,  1.24s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 20/32 [00:25<00:15,  1.30s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:51 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 21/32 [00:26<00:13,  1.20s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [00:27<00:10,  1.10s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:53 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 23/32 [00:28<00:10,  1.16s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:54 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 24/32 [00:29<00:08,  1.06s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:55 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25/32 [00:30<00:07,  1.00s/trial, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 26/32 [00:31<00:05,  1.03trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 27/32 [00:32<00:04,  1.08trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [00:33<00:03,  1.12trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:58 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [00:34<00:02,  1.14trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:47:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 30/32 [00:34<00:01,  1.14trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:48:00 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 31/32 [00:35<00:00,  1.14trial/s, best loss: -0.9583333333333334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:48:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:37<00:00,  1.17s/trial, best loss: -0.9583333333333334]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier_type': 0,\n",
       " 'dtree_criterion': 1,\n",
       " 'dtree_max_depth': 0,\n",
       " 'dtree_min_samples_split': 7}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective, space=search_space, algo=algo, max_evals=32, trials=trials\n",
    ")\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 Best Training Models\n",
    "\n",
    "1. 7a2f884e11b9483b9ea730a06ae1fcdf\n",
    "2. 1ba90b7e0ade4ea181f5ce14259a45fb\n",
    "3. dbb34c6780f84f35abcc1aa0e37e881b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Validation Set to find the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "sepal length\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "X_redcued_val = X_val.copy()\n",
    "VIF = [0]\n",
    "while len(VIF) > 0:\n",
    "    X_numeric = pd.DataFrame()\n",
    "    for col in X_redcued_val.columns:\n",
    "        # Force everything through string conversion to be safe\n",
    "        X_numeric[col] = pd.to_numeric(\n",
    "            X_train[col].astype(str), errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    # Now calculate VIF\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_numeric.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X_numeric.values, i)\n",
    "        for i in range(X_numeric.shape[1])\n",
    "    ]\n",
    "    vif_test = vif_data.set_index(\"Feature\").sort_values(\n",
    "        by=\"VIF\", ascending=False\n",
    "    )\n",
    "    if vif_test.max().iloc[0] > 5:\n",
    "        print(VIF)\n",
    "        VIF = vif_test.idxmax().iloc[0]\n",
    "        X_redcued_val.drop(VIF, axis=1, inplace=True)\n",
    "    else:\n",
    "        print(\"Stopping\")\n",
    "        VIF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_1_logged_model = \"runs:/7a2f884e11b9483b9ea730a06ae1fcdf/better_models\"  # replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "top3_1_loaded_model = mlflow.pyfunc.load_model(top3_1_logged_model)\n",
    "\n",
    "top3_2_logged_model = \"runs:/1ba90b7e0ade4ea181f5ce14259a45fb/better_models\"  # replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "top3_2_loaded_model = mlflow.pyfunc.load_model(top3_2_logged_model)\n",
    "\n",
    "top3_3_logged_model = \"runs:/dbb34c6780f84f35abcc1aa0e37e881b/better_models\"  # replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "top3_3_loaded_model = mlflow.pyfunc.load_model(top3_3_logged_model)\n",
    "\n",
    "model_1_train = mlflow.sklearn.load_model(top3_1_logged_model)\n",
    "model_2_train = mlflow.sklearn.load_model(top3_2_logged_model)\n",
    "model_3_train = mlflow.sklearn.load_model(top3_3_logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:52:33 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:52:34 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:52:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    counter = 0\n",
    "    for model in [model_1_train, model_2_train, model_3_train]:\n",
    "        counter += 1\n",
    "        params = model.get_params()\n",
    "        for phase in [\"validation\"]:\n",
    "            if phase == \"validation\":\n",
    "                acc = cross_val_score(model, X_redcued_val, y_val).mean()\n",
    "            mlflow.set_tag(\"Model\", \"dt\")\n",
    "            mlflow.set_tag(\"Data\", \"validation\")\n",
    "            mlflow.log_params(model.get_params())\n",
    "            mlflow.log_metric(\"accuracy\", acc)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"better_models\")\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model according to Validation\n",
    "\n",
    "1. 18344d4723fb4fb69155783ae8ddd437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running All models on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_redcued_test = X_test.copy()\n",
    "VIF = [0]\n",
    "while len(VIF) > 0:\n",
    "    X_numeric = pd.DataFrame()\n",
    "    for col in X_redcued_test.columns:\n",
    "        # Force everything through string conversion to be safe\n",
    "        X_numeric[col] = pd.to_numeric(\n",
    "            X_train[col].astype(str), errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    # Now calculate VIF\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_numeric.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X_numeric.values, i)\n",
    "        for i in range(X_numeric.shape[1])\n",
    "    ]\n",
    "    vif_test = vif_data.set_index(\"Feature\").sort_values(\n",
    "        by=\"VIF\", ascending=False\n",
    "    )\n",
    "    if vif_test.max().iloc[0] > 5:\n",
    "        # print(VIF)\n",
    "        VIF = vif_test.idxmax().iloc[0]\n",
    "        X_redcued_test.drop(VIF, axis=1, inplace=True)\n",
    "    else:\n",
    "        # print(\"Stopping\")\n",
    "        VIF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_1_logged_model = \"runs:/18344d4723fb4fb69155783ae8ddd437/better_models\"  # replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "top3_1_loaded_model = mlflow.pyfunc.load_model(top3_1_logged_model)\n",
    "\n",
    "top3_2_logged_model = \"runs:/c7ab29591da9434ba65d90e8e3750fb9/better_models\"  # replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "top3_2_loaded_model = mlflow.pyfunc.load_model(top3_2_logged_model)\n",
    "\n",
    "top3_3_logged_model = \"runs:/10b5fccad25f469ab55ea8f8c1b97586/better_models\"  # replace with one of your models\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "top3_3_loaded_model = mlflow.pyfunc.load_model(top3_3_logged_model)\n",
    "\n",
    "best_model = mlflow.sklearn.load_model(top3_1_logged_model)\n",
    "model_2 = mlflow.sklearn.load_model(top3_2_logged_model)\n",
    "model_3 = mlflow.sklearn.load_model(top3_3_logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 22:54:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:37 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:38 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:41 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/03/21 22:54:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "# mlflow.set_experiment(\"Lab2-student_performance_output\")\n",
    "with mlflow.start_run():\n",
    "    counter = 0\n",
    "    for model in [best_model, model_2, model_3]:\n",
    "        counter += 1\n",
    "        params = model.get_params()\n",
    "        for phase in [\"train\", \"validation\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                acc = cross_val_score(model, X_redcued_train, y_train).mean()\n",
    "            elif phase == \"validation\":\n",
    "                acc = cross_val_score(model, X_redcued_val, y_val).mean()\n",
    "            elif phase == \"test\":\n",
    "                acc = cross_val_score(best_model, X_redcued_test, y_test).mean()\n",
    "            if counter == 1:\n",
    "                mlflow.set_tag(\"Model_Variation\", \"Best\")\n",
    "            if counter == 2:\n",
    "                mlflow.set_tag(\"Model_Variation\", \"2nd_Best\")\n",
    "            if counter == 3:\n",
    "                mlflow.set_tag(\"Model_Variation\", \"3rd_Best\")\n",
    "            mlflow.set_tag(\"Model\", \"dt\")\n",
    "            mlflow.set_tag(\"Data\", phase)\n",
    "            mlflow.log_params(model.get_params())\n",
    "            mlflow.log_metric(\"accuracy\", acc)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"better_models\")\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staging the best model on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Lab2_Best_Model'.\n",
      "Created version '1' of model 'Lab2_Best_Model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1742622184659, current_stage='None', description=None, last_updated_timestamp=1742622184659, name='Lab2_Best_Model', run_id='e311596193dd48fca9cadd160c8e96d1', run_link=None, source='/Users/skier/MSDS/Spring2/Spring2-MSDS-MLOps/labs/lab2/mlruns/11/e311596193dd48fca9cadd160c8e96d1/artifacts/artifacts/better_models', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runid = \"18344d4723fb4fb69155783ae8ddd437\"\n",
    "mod_path = f\"runs:/{runid}/artifacts/better_models\"\n",
    "mlflow.register_model(model_uri=mod_path, name=\"Lab2_Best_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
